
<center> 
    <h1> Neuromorphic computing </h1>
    <hr />
    <h2>The strange interplay between brains and machines.</h2>
</center>

Our "cognitive architechtures" - that is, the operation of our individual neurons, their arrangement, neuronal circuits, subsystems, folds, lobes, and the connections between these lobes - is what makes humans truely special and gives us our intelligence. We are not the only species to have neurons, but we are unique in our cognitive architechtures. There are obvious and often unfortunate effects of being born with or developing different cognitive architechtures. Psychadelic compounds can literally modify our cognitive architechture (slightly), and allow us to inhabit fascinating and normally-inaccessible regions of the "conciousness space." 

Computers, too, have a cognitive architechture, and it has a name:

<center><h2>The Von Neumann Architechture</h2></center>
<img class="centeredImage" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Von_Neumann_Architecture.svg/1200px-Von_Neumann_Architecture.svg.png" />
<hr />
<center><h2>The Harvard architechture</h2> </center>
<img class="centeredImage" src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Harvard_architecture.svg/362px-Harvard_architecture.svg.png"/>
<hr />

These simple diagams roughly convey the **Von Neumann** and **Harvard** architechtures, which, combined with the specifics of operation of transistors and logic gates, form the foundation of nearly all modern computers. Like any given cognitive architechture, these arrangements have strengths and weaknesses. For example, both architechtures are good at storing information for long periods of time. The Von Neumann architechture is cheaper and easier to manufacture by industrial means, and it requires less physical space than the Harvard architechture. However, it is slower due to bottlenecks related to bussing data between computer chips. In the very same way, the human cognitive architechture has different characteristics, pros, and cons due to the way it evolved. The human mind evolved to be able to solve certain types of problems (facial recognition, speech recognition, spacial reasoning tasks, etc.) extremely easily and efficiently, and, due to its flexible and *neuroplastic* nature, we can use it to accomplish tasks that it did not really evolve to do, such as arithmetic and statistics. Sometimes, we do this effectively, but sometimes our cognitive architechture greatly fails us (think of the work of [Daniel Khaneman and Amos Tsversky](https://www.amazon.com/Undoing-Project-Friendship-Changed-Minds/dp/0393254593) ). Another drawback of the human mind is its speed and limited scale: the maximum firing speed of a neuron is about 100 m/s (and as slow as 1 m/s), and it isn't exactly possible to build a brain with 100 times the processing power of a normal brain. This, along with the finite plasticity of our brains, puts an upper bound on human intelligence and speed of thinking. Despite these limitations, we have wrangled our minds into accomplishing *incredible* things. The same concept is technically true for computers. A computer architechture really is not naturally suited for [Spatial and verbal reasoning](https://arxiv.org/abs/1904.12584) , [object recognition](https://arxiv.org/pdf/1907.09408.pdf) , [playing Go](https://deepmind.com/research/case-studies/alphago-the-story-so-far) , or [making sense of and generating natural language](https://openai.com/projects/), but they are now able to do all these things. We have even developed **diverse-purpose architechtures** - for example, *transformer* models are effective not only in natural language tasks but also in [image tasks](https://openai.com/blog/image-gpt/). In fact, it has been [proven](https://en.wikipedia.org/wiki/Universal_approximation_theorem) that neural networks are, in theory, **universal function approximators** (though not in practice). However, imagine if we were to create an architechture that combined the strengths of computers, and those of the human mind. Or, if we were to come up with an alien architechture that isn't comparable to either. Imagine the implications of doing so much more with so much less compute, and then scaling that up, overclocking the GPUs, etc. This, intuitively, seems to be a plausible path toward human-level AI. Anthing even *approaching* human level would have a tremendous impact- imagine taking the mind of an average physicist and having him work on a difficult problem confronting humanity for 100,000 years, all in the span of one day of real-world time (ignore the ethical implications for the time being). Of course, it's not so simple, but advances are consistently made in the field of neuromorphic computing. Let's take a look at a few...
<hr />
